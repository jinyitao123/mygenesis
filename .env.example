# LLM API配置 (云端大模型 - 负责逻辑与规则)
# 使用兼容OpenAI格式的Gemini API
LLM_API_KEY=your-api-key-here
LLM_BASE_URL=http://XXX/v1beta

# 云端模型选择 (负责逻辑推理、意图解析、世界生成)
WORLD_GEN_MODEL=models/gemini-2.5-flash-lite
INTENT_MODEL=models/gemini-2.5-flash-lite

# 本地 Ollama 配置 (本地小模型 - 负责对话与摘要)
# 默认使用 qwen3:14b (中文能力强，14B参数)
OLLAMA_CHAT_MODEL=qwen3:14b
OLLAMA_BASE_URL=http://localhost:11434

# 备选：如果显存不够，可以使用更小的模型
# OLLAMA_CHAT_MODEL=qwen2.5:7b  # 7B参数，速度更快
# OLLAMA_CHAT_MODEL=qwen2.5:3b  # 3B参数，低配电脑也能跑

# Neo4j数据库配置 (左脑 - 图数据库)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your-password-here

# PostgreSQL向量数据库配置 (右脑 - 记忆存储)
# 格式: postgresql+asyncpg://user:password@host:port/database
VECTOR_DB_URL=postgresql+asyncpg://postgres:your-password@localhost:5432/smartcleankb

# 嵌入模型配置 (用于向量化)
EMBEDDING_MODEL=nomic-embed-text-v2-moe
EMBEDDING_DIMENSIONS=768
